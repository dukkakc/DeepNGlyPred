{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1680\n",
      "0\n",
      "4200\n",
      "0\n",
      "(447, 1188) (447,)\n",
      "Matthews Correlation :  0.5666737216241037\n",
      "Confusion Matrix : \n",
      " [[233  47]\n",
      " [ 44 123]]\n",
      "Accuracy on test set:    0.796420581655481\n",
      "Sensitivity:    0.7365269461077845 \t Specificity:    0.8321428571428572\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.83      0.84       280\n",
      "           1       0.72      0.74      0.73       167\n",
      "\n",
      "    accuracy                           0.80       447\n",
      "   macro avg       0.78      0.78      0.78       447\n",
      "weighted avg       0.80      0.80      0.80       447\n",
      "\n",
      "0 yes\n",
      "1 yes\n",
      "2 no\n",
      "3 no\n",
      "4 yes\n",
      "5 no\n",
      "6 yes\n",
      "7 yes\n",
      "8 yes\n",
      "9 yes\n",
      "10 no\n",
      "11 yes\n",
      "12 no\n",
      "13 no\n",
      "14 no\n",
      "15 no\n",
      "16 yes\n",
      "17 no\n",
      "18 yes\n",
      "19 yes\n",
      "20 yes\n",
      "21 yes\n",
      "22 no\n",
      "23 no\n",
      "24 yes\n",
      "25 yes\n",
      "26 yes\n",
      "27 yes\n",
      "28 no\n",
      "29 no\n",
      "30 yes\n",
      "31 yes\n",
      "32 yes\n",
      "33 yes\n",
      "34 no\n",
      "35 no\n",
      "36 no\n",
      "37 yes\n",
      "38 yes\n",
      "39 yes\n",
      "40 yes\n",
      "41 yes\n",
      "42 yes\n",
      "43 yes\n",
      "44 yes\n",
      "45 yes\n",
      "46 no\n",
      "47 no\n",
      "48 no\n",
      "49 yes\n",
      "50 yes\n",
      "51 yes\n",
      "52 yes\n",
      "53 yes\n",
      "54 yes\n",
      "55 yes\n",
      "56 yes\n",
      "57 yes\n",
      "58 yes\n",
      "59 yes\n",
      "60 yes\n",
      "61 yes\n",
      "62 yes\n",
      "63 yes\n",
      "64 no\n",
      "65 no\n",
      "66 no\n",
      "67 yes\n",
      "68 yes\n",
      "69 yes\n",
      "70 no\n",
      "71 yes\n",
      "72 yes\n",
      "73 yes\n",
      "74 no\n",
      "75 no\n",
      "76 yes\n",
      "77 no\n",
      "78 yes\n",
      "79 no\n",
      "80 no\n",
      "81 yes\n",
      "82 yes\n",
      "83 yes\n",
      "84 yes\n",
      "85 yes\n",
      "86 yes\n",
      "87 yes\n",
      "88 yes\n",
      "89 yes\n",
      "90 yes\n",
      "91 yes\n",
      "92 yes\n",
      "93 yes\n",
      "94 yes\n",
      "95 yes\n",
      "96 yes\n",
      "97 no\n",
      "98 no\n",
      "99 yes\n",
      "100 yes\n",
      "101 yes\n",
      "102 yes\n",
      "103 yes\n",
      "104 yes\n",
      "105 no\n",
      "106 yes\n",
      "107 yes\n",
      "108 yes\n",
      "109 yes\n",
      "110 yes\n",
      "111 yes\n",
      "112 yes\n",
      "113 no\n",
      "114 no\n",
      "115 yes\n",
      "116 yes\n",
      "117 yes\n",
      "118 no\n",
      "119 no\n",
      "120 yes\n",
      "121 yes\n",
      "122 no\n",
      "123 no\n",
      "124 yes\n",
      "125 yes\n",
      "126 no\n",
      "127 yes\n",
      "128 no\n",
      "129 no\n",
      "130 no\n",
      "131 yes\n",
      "132 yes\n",
      "133 yes\n",
      "134 yes\n",
      "135 yes\n",
      "136 yes\n",
      "137 yes\n",
      "138 yes\n",
      "139 yes\n",
      "140 yes\n",
      "141 yes\n",
      "142 yes\n",
      "143 yes\n",
      "144 yes\n",
      "145 yes\n",
      "146 no\n",
      "147 yes\n",
      "148 yes\n",
      "149 yes\n",
      "150 yes\n",
      "151 no\n",
      "152 yes\n",
      "153 yes\n",
      "154 yes\n",
      "155 yes\n",
      "156 yes\n",
      "157 yes\n",
      "158 yes\n",
      "159 yes\n",
      "160 yes\n",
      "161 no\n",
      "162 yes\n",
      "163 yes\n",
      "164 yes\n",
      "165 yes\n",
      "166 yes\n",
      "167 yes\n",
      "168 no\n",
      "169 no\n",
      "170 no\n",
      "171 yes\n",
      "172 no\n",
      "173 no\n",
      "174 no\n",
      "175 no\n",
      "176 no\n",
      "177 no\n",
      "178 no\n",
      "179 no\n",
      "180 no\n",
      "181 no\n",
      "182 no\n",
      "183 yes\n",
      "184 no\n",
      "185 no\n",
      "186 no\n",
      "187 no\n",
      "188 yes\n",
      "189 no\n",
      "190 no\n",
      "191 no\n",
      "192 yes\n",
      "193 no\n",
      "194 no\n",
      "195 no\n",
      "196 no\n",
      "197 no\n",
      "198 no\n",
      "199 yes\n",
      "200 no\n",
      "201 no\n",
      "202 yes\n",
      "203 yes\n",
      "204 no\n",
      "205 yes\n",
      "206 yes\n",
      "207 no\n",
      "208 no\n",
      "209 no\n",
      "210 yes\n",
      "211 no\n",
      "212 yes\n",
      "213 yes\n",
      "214 yes\n",
      "215 no\n",
      "216 yes\n",
      "217 yes\n",
      "218 no\n",
      "219 no\n",
      "220 yes\n",
      "221 yes\n",
      "222 no\n",
      "223 no\n",
      "224 no\n",
      "225 no\n",
      "226 no\n",
      "227 yes\n",
      "228 no\n",
      "229 no\n",
      "230 no\n",
      "231 no\n",
      "232 no\n",
      "233 no\n",
      "234 no\n",
      "235 no\n",
      "236 no\n",
      "237 no\n",
      "238 no\n",
      "239 no\n",
      "240 no\n",
      "241 no\n",
      "242 no\n",
      "243 no\n",
      "244 no\n",
      "245 no\n",
      "246 no\n",
      "247 no\n",
      "248 no\n",
      "249 no\n",
      "250 no\n",
      "251 no\n",
      "252 no\n",
      "253 no\n",
      "254 no\n",
      "255 no\n",
      "256 no\n",
      "257 no\n",
      "258 no\n",
      "259 no\n",
      "260 no\n",
      "261 no\n",
      "262 no\n",
      "263 no\n",
      "264 no\n",
      "265 no\n",
      "266 no\n",
      "267 no\n",
      "268 no\n",
      "269 no\n",
      "270 no\n",
      "271 no\n",
      "272 no\n",
      "273 no\n",
      "274 no\n",
      "275 no\n",
      "276 no\n",
      "277 no\n",
      "278 no\n",
      "279 no\n",
      "280 no\n",
      "281 no\n",
      "282 no\n",
      "283 yes\n",
      "284 no\n",
      "285 no\n",
      "286 no\n",
      "287 no\n",
      "288 no\n",
      "289 no\n",
      "290 no\n",
      "291 no\n",
      "292 no\n",
      "293 yes\n",
      "294 yes\n",
      "295 no\n",
      "296 no\n",
      "297 no\n",
      "298 no\n",
      "299 no\n",
      "300 no\n",
      "301 no\n",
      "302 no\n",
      "303 no\n",
      "304 no\n",
      "305 no\n",
      "306 no\n",
      "307 no\n",
      "308 no\n",
      "309 no\n",
      "310 no\n",
      "311 no\n",
      "312 no\n",
      "313 no\n",
      "314 no\n",
      "315 no\n",
      "316 no\n",
      "317 no\n",
      "318 no\n",
      "319 no\n",
      "320 no\n",
      "321 no\n",
      "322 no\n",
      "323 no\n",
      "324 no\n",
      "325 yes\n",
      "326 no\n",
      "327 no\n",
      "328 yes\n",
      "329 no\n",
      "330 no\n",
      "331 no\n",
      "332 no\n",
      "333 no\n",
      "334 no\n",
      "335 no\n",
      "336 no\n",
      "337 no\n",
      "338 no\n",
      "339 no\n",
      "340 no\n",
      "341 no\n",
      "342 no\n",
      "343 no\n",
      "344 yes\n",
      "345 no\n",
      "346 no\n",
      "347 no\n",
      "348 no\n",
      "349 no\n",
      "350 no\n",
      "351 no\n",
      "352 no\n",
      "353 no\n",
      "354 no\n",
      "355 no\n",
      "356 no\n",
      "357 no\n",
      "358 no\n",
      "359 no\n",
      "360 no\n",
      "361 no\n",
      "362 no\n",
      "363 no\n",
      "364 no\n",
      "365 no\n",
      "366 yes\n",
      "367 no\n",
      "368 yes\n",
      "369 no\n",
      "370 no\n",
      "371 no\n",
      "372 yes\n",
      "373 yes\n",
      "374 yes\n",
      "375 no\n",
      "376 no\n",
      "377 no\n",
      "378 no\n",
      "379 no\n",
      "380 no\n",
      "381 yes\n",
      "382 yes\n",
      "383 yes\n",
      "384 no\n",
      "385 no\n",
      "386 yes\n",
      "387 no\n",
      "388 no\n",
      "389 no\n",
      "390 no\n",
      "391 no\n",
      "392 no\n",
      "393 no\n",
      "394 no\n",
      "395 no\n",
      "396 no\n",
      "397 no\n",
      "398 yes\n",
      "399 no\n",
      "400 yes\n",
      "401 no\n",
      "402 no\n",
      "403 no\n",
      "404 no\n",
      "405 no\n",
      "406 no\n",
      "407 no\n",
      "408 no\n",
      "409 no\n",
      "410 no\n",
      "411 no\n",
      "412 no\n",
      "413 no\n",
      "414 yes\n",
      "415 no\n",
      "416 no\n",
      "417 no\n",
      "418 no\n",
      "419 no\n",
      "420 yes\n",
      "421 no\n",
      "422 no\n",
      "423 no\n",
      "424 no\n",
      "425 no\n",
      "426 yes\n",
      "427 no\n",
      "428 no\n",
      "429 no\n",
      "430 yes\n",
      "431 yes\n",
      "432 yes\n",
      "433 no\n",
      "434 yes\n",
      "435 yes\n",
      "436 no\n",
      "437 yes\n",
      "438 yes\n",
      "439 no\n",
      "440 no\n",
      "441 yes\n",
      "442 no\n",
      "443 no\n",
      "444 no\n",
      "445 no\n",
      "446 no\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from numpy import sort\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import *\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, classification_report,auc\n",
    "%matplotlib inline\n",
    "import keras\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.utils import shuffle\n",
    "from keras.layers import Dense, Bidirectional,Dense, LSTM, Activation, Dropout, Flatten\n",
    "from keras.layers import LeakyReLU\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf\n",
    "from keras.regularizers import l2\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.constraints import maxnorm\n",
    "from keras.models import Sequential \n",
    "from keras.layers import LSTM\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "from keras.regularizers import l2\n",
    "from keras.models import Model\n",
    "from keras.applications import mobilenet_v2, mobilenet, resnet50, densenet\n",
    "from keras.layers import Dense, MaxPooling2D, Conv2D, Flatten, \\\n",
    "    BatchNormalization, Activation, GlobalAveragePooling2D, DepthwiseConv2D, \\\n",
    "    Dropout, ReLU, Concatenate, Input, add, Conv1D, MaxPooling1D\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import TimeDistributed\n",
    "\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from keras.callbacks import CSVLogger\n",
    "from datetime import datetime\n",
    "\n",
    "import cv2\n",
    "import os.path\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from scipy.spatial import distance\n",
    "import scipy.io as sio\n",
    "\n",
    "\n",
    "df_test = pd.read_csv(\"All_feature_Independent_dataframe.csv\")\n",
    "\n",
    "X_test_NetSurfP2 = df_test.iloc[:,2100:2428]\n",
    "\n",
    "y_test_NetSurfP2 = df_test[\"Target\"]\n",
    "\n",
    "\n",
    "print(X_test_NetSurfP2.isnull().sum().sum())\n",
    "X_test_NetSurfP2.fillna(0,inplace=True)\n",
    "print(X_test_NetSurfP2.isnull().sum().sum())\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "\n",
    "X_test_NetSurfP2 = scaler.fit_transform(X_test_NetSurfP2)\n",
    "\n",
    "\n",
    "X_test_NetSurfP2 = np.array(X_test_NetSurfP2)\n",
    "y_test_NetSurfP2 = np.array(y_test_NetSurfP2)\n",
    "\n",
    "X_test_PSSM_test = df_test.iloc[:,1280:2100]\n",
    "\n",
    "y_test_PSSM = df_test[\"Target\"]\n",
    "\n",
    "print(X_test_PSSM_test.isnull().sum().sum())\n",
    "X_test_PSSM_test.fillna(0,inplace=True)\n",
    "print(X_test_PSSM_test.isnull().sum().sum())\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "\n",
    "X_test_PSSM_test = scaler.fit_transform(X_test_PSSM_test)\n",
    "\n",
    "\n",
    "X_test_PSSM_test = np.array(X_test_PSSM_test)\n",
    "y_test_PSSM = np.array(y_test_PSSM)\n",
    "\n",
    "X_test_Gapped_Dipeptide = df_test.iloc[:,2428:2468]\n",
    "\n",
    "y_test_Gapped_Dipeptide = df_test[\"Target\"]\n",
    "\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "\n",
    "X_test_Gapped_Dipeptide = scaler.fit_transform(X_test_Gapped_Dipeptide)\n",
    "\n",
    "\n",
    "X_test_Gapped_Dipeptide = np.array(X_test_Gapped_Dipeptide)\n",
    "y_test_Gapped_Dipeptide = np.array(y_test_Gapped_Dipeptide)\n",
    "\n",
    "X_test_PSSM_NetSurfP2_Gapped_Dipeptide = np.hstack((X_test_PSSM_test,X_test_NetSurfP2,X_test_Gapped_Dipeptide))\n",
    "\n",
    "y_test_PSSM_NetSurfP2_Gapped_Dipeptide = y_test_Gapped_Dipeptide\n",
    "\n",
    "X_test = X_test_PSSM_NetSurfP2_Gapped_Dipeptide\n",
    "\n",
    "y_test = y_test_PSSM_NetSurfP2_Gapped_Dipeptide\n",
    "\n",
    "print(X_test.shape,y_test.shape)\n",
    "\n",
    "X_test = X_test.reshape(X_test.shape[0],1188,1)\n",
    "\n",
    "model = keras.models.load_model(\"lstm_run_agian_molecules_paper_final_model__9__.h5\")\n",
    "\n",
    "Y_pred = model.predict(X_test)\n",
    "Y_pred = (Y_pred > 0.5)\n",
    "y_pred = [np.argmax(y, axis=None, out=None) for y in Y_pred]\n",
    "y_pred = np.array(y_pred)\n",
    "print(\"Matthews Correlation : \",matthews_corrcoef(y_test, y_pred))\n",
    "print(\"Confusion Matrix : \\n\",confusion_matrix(y_test, y_pred))\n",
    "print(\"Accuracy on test set:   \",accuracy_score(y_test, y_pred))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "TP = cm[1][1]\n",
    "TN = cm[0][0]\n",
    "FP = cm[0][1]\n",
    "FN = cm[1][0]\n",
    "\n",
    "mcc = matthews_corrcoef(y_test, y_pred)\n",
    "\n",
    "Sensitivity = TP/(TP+FN)\n",
    "\n",
    "Specificity = TN/(TN+FP)\n",
    "\n",
    "print(\"Sensitivity:   \",Sensitivity,\"\\t\",\"Specificity:   \",Specificity)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
